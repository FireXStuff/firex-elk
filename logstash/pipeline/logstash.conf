input {
	tcp {
		port => 5000
	}
        kafka {
                bootstrap_servers => "sjc-asr-001:9092,sjc-asr-002:9092,sjc-asr-003:9092,sjc-asr-005:9092,sjc-asr-006:9092"
                topics => "firex-events-all"
                codec => "json"
        }
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => elastic
		password => changeme
                index => "firexindex-%{+YYYY.MM.dd}"
                manage_template => true
                template => "/usr/share/logstash/pipeline/templates/firex_template.json"
                template_name => "firexindex-*"
                template_overwrite => false
	}
        stdout { codec => rubydebug }
}

filter {

     split {
       field => "EVENTS"
     }

     aggregate {
       task_id => "%{[EVENTS][UUID]}"
       code => "
             # Update aggregated map based on event
             event.to_hash.each do |key,value|
                  if value.is_a?(Hash)
                        map[key] ||= {}
                        map[key].merge!(value)
                  else
                    map[key] = value
                  end
             end

             map['EVENTS'].each do |key, value|
               map[key] = value
             end
	     map.delete('EVENTS')

             map['DATA'].each do |key, value|
               map[key] = value
             end
	     map.delete('DATA')

             if map['type'] == 'task-received' or map['type'] == 'task-started'
                map['_started'] = true
             end
           "
       timeout => 259200
       push_map_as_event_on_timeout => true
       timeout_tags => ['_aggregatetimeout']
       timeout_task_id_field => "UUID" 
       timeout_code => "
                       event.set('type', 'task-timeout')
                       event.set('_completed', true)
                       "
     }

     # We got a final event, copy map back into the event and flag it for saving
     if [EVENTS][DATA][type] == 'task-succeeded' or [EVENTS][DATA][type] == 'task-revoked' or [EVENTS][DATA][type] == 'task-failed' {
       aggregate {
         task_id => "%{[EVENTS][UUID]}"
         code => "
             # Update aggregated map based on event
             event.to_hash.each do |key,value|
                  if value.is_a?(Hash)
                        map[key] ||= {}
                        map[key].merge!(value)
                  else
                    map[key] = value
                  end
             end

             map['EVENTS'].each do |key, value|
               map[key] = value
             end
	     map.delete('EVENTS')
             event.remove('EVENTS')

             map['DATA'].each do |key, value|
               map[key] = value
             end
	     map.delete('DATA')

             map['not_failed'] = 1
	     if map['state'] == 'SUCCESS'
               map['success'] = 1
             else
               map['success'] = 0
             end

	     if map['state'] == 'FAILURE'
               map['failure'] = 1
               map['not_failed'] = 0
             else
               map['failure'] = 0
             end

	     if map['state'] == 'REVOKED'
               map['revoked'] = 1
             else
               map['revoked'] = 0
             end

             map.to_hash.each do |key,value|
               event.set(key, value)
             end   
             event.set('_completed', true)
             
            "
         end_of_task => true
       }
     }

     ruby {
       code => "
            unless event.to_hash.has_key?('_started') and event.to_hash.has_key?('_completed') 
               event.cancel()
            end
            "
     }
}
